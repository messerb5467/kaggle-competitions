{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GenderedPronounsDataExploration.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMZwflXdO67uZQ9JTLpZP1g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/messerb5467/kaggle-competitions/blob/main/gendered-coref/GenderedPronounsDataExploration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4SBdUCJBnYy"
      },
      "source": [
        "# Overview\n",
        "In this notebook, I'm going to work throught the kaggle [gendered pronoun resolution competition](https://www.kaggle.com/c/gendered-pronoun-resolution/data). Motivations are that mostly for fun and learning, but fairness in AI is a very important topic, especially with the wake of numerous upsets I will leave to the reader to investigate more on their own.\n",
        "\n",
        "# Stepping into the problem\n",
        "\n",
        "Analyzing this from a very high level perspective, this is a very targeted problem that shouldn't require the use of multiple models arranged in a hierarchical or interlacing nature as I'm not trying to take the results of one model, say a voice synthesis focused model and translate that into something that a backend model, a natural language model, for further understanding of what's going on in my use case.\n",
        "\n",
        "Before I make any more judgements though, I really do need to bring in the dataset for analysis to understand precisely what model needs used. My initial thought based on the provided examples from the course overview page are that a bidirectional lstm could be very useful towards addressing this particular use case."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efvZPjgwfsuu"
      },
      "source": [
        "# Bringing in the data\n",
        "The data itself is available in a couple locations (the kaggle dashboard as well as a [linked github repo](https://github.com/google-research-datasets/gap-coreference)) and for ease of reproducibility, I'm going to focus on importing the data from the github repo using the below command."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mf_es4nvfx9H",
        "outputId": "c8b17011-2474-44f2-ba41-e82b3291bab2"
      },
      "source": [
        "!git clone https://github.com/google-research-datasets/gap-coreference"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'gap-coreference'...\n",
            "remote: Enumerating objects: 19, done.\u001b[K\n",
            "remote: Total 19 (delta 0), reused 0 (delta 0), pack-reused 19\u001b[K\n",
            "Unpacking objects: 100% (19/19), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_G-tDdGgYYA"
      },
      "source": [
        "## Reviewing the data\n",
        "An initial look at the README.md provided in the github repo presupposes this as tab-separated values instead of the normal comma-separated values dataset, but overall does not provide any damper at really looking into this overall problem. It should be incredibly easy to actually get this thing imported, reviewed and cleaned.\n",
        "\n",
        "While I know that I eventually want to manipulate this in tensorflow, I just want to start by getting an idea of what this dataset looks like in pandas. If I were to scale this out or do this purely in tensorflow, I would rely on the Tensorflow datasets api to bring this in and clean and even Tensorflow Data validation to get a better look of what's going on inside of the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahVRXct0iPzJ"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aihdoM7SiR5h"
      },
      "source": [
        "df_train = pd.read_csv('gap-coreference/gap-development.tsv', sep='\\t')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "id": "TfBpHhAliiUr",
        "outputId": "69d54eca-d62b-48b4-e81b-1d812a0d4481"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Text</th>\n",
              "      <th>Pronoun</th>\n",
              "      <th>Pronoun-offset</th>\n",
              "      <th>A</th>\n",
              "      <th>A-offset</th>\n",
              "      <th>A-coref</th>\n",
              "      <th>B</th>\n",
              "      <th>B-offset</th>\n",
              "      <th>B-coref</th>\n",
              "      <th>URL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>development-1</td>\n",
              "      <td>Zoe Telford -- played the police officer girlf...</td>\n",
              "      <td>her</td>\n",
              "      <td>274</td>\n",
              "      <td>Cheryl Cassidy</td>\n",
              "      <td>191</td>\n",
              "      <td>True</td>\n",
              "      <td>Pauline</td>\n",
              "      <td>207</td>\n",
              "      <td>False</td>\n",
              "      <td>http://en.wikipedia.org/wiki/List_of_Teachers_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>development-2</td>\n",
              "      <td>He grew up in Evanston, Illinois the second ol...</td>\n",
              "      <td>His</td>\n",
              "      <td>284</td>\n",
              "      <td>MacKenzie</td>\n",
              "      <td>228</td>\n",
              "      <td>True</td>\n",
              "      <td>Bernard Leach</td>\n",
              "      <td>251</td>\n",
              "      <td>False</td>\n",
              "      <td>http://en.wikipedia.org/wiki/Warren_MacKenzie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>development-3</td>\n",
              "      <td>He had been reelected to Congress, but resigne...</td>\n",
              "      <td>his</td>\n",
              "      <td>265</td>\n",
              "      <td>Angeloz</td>\n",
              "      <td>173</td>\n",
              "      <td>False</td>\n",
              "      <td>De la Sota</td>\n",
              "      <td>246</td>\n",
              "      <td>True</td>\n",
              "      <td>http://en.wikipedia.org/wiki/Jos%C3%A9_Manuel_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>development-4</td>\n",
              "      <td>The current members of Crime have also perform...</td>\n",
              "      <td>his</td>\n",
              "      <td>321</td>\n",
              "      <td>Hell</td>\n",
              "      <td>174</td>\n",
              "      <td>False</td>\n",
              "      <td>Henry Rosenthal</td>\n",
              "      <td>336</td>\n",
              "      <td>True</td>\n",
              "      <td>http://en.wikipedia.org/wiki/Crime_(band)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>development-5</td>\n",
              "      <td>Her Santa Fe Opera debut in 2005 was as Nuria ...</td>\n",
              "      <td>She</td>\n",
              "      <td>437</td>\n",
              "      <td>Kitty Oppenheimer</td>\n",
              "      <td>219</td>\n",
              "      <td>False</td>\n",
              "      <td>Rivera</td>\n",
              "      <td>294</td>\n",
              "      <td>True</td>\n",
              "      <td>http://en.wikipedia.org/wiki/Jessica_Rivera</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              ID  ...                                                URL\n",
              "0  development-1  ...  http://en.wikipedia.org/wiki/List_of_Teachers_...\n",
              "1  development-2  ...      http://en.wikipedia.org/wiki/Warren_MacKenzie\n",
              "2  development-3  ...  http://en.wikipedia.org/wiki/Jos%C3%A9_Manuel_...\n",
              "3  development-4  ...          http://en.wikipedia.org/wiki/Crime_(band)\n",
              "4  development-5  ...        http://en.wikipedia.org/wiki/Jessica_Rivera\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8JAzkR0jb8A"
      },
      "source": [
        "Looking at the above data, I have some thoughts at really working through this data cleaning. Keep these thoughts in mind depending on how your data is made in production as you may have to recreate these exact steps when making the port over into your own data pipeline. Here's the steps in detail:\n",
        "\n",
        "1. Dropping the URL field - Without any more specific business context, I don't have much I can really do with this. Thus, let's get it out of the way.\n",
        "2. Understanding statistics of the different offset lengths into the text and tokenizing it - Sequence models like RNNs and LSTMs don't perform incredibly well when we need to perform long-range time dependencies. Normal is oftentimes described as 400-500+ and we can get through this issue by tokenizing the output to get rid of any filler words. You can also use an embedding for dimensionality reduction here (preferably pre-trained so we don't spend extra time wasting CPU cycles when bigger companies have already done this on massive datasets the likes of which you'll only see in something like an HPC or research environment), but I personally see this as more of a text-scanning problem than I do as something that would be solved by an embedding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhjnlh-ui05a"
      },
      "source": [
        "df_train = df_train.drop(columns=['URL'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "lIjqXpSHmBSB",
        "outputId": "fabcb6ab-59ea-40e0-b19e-91722bac0daa"
      },
      "source": [
        "df_train[['Pronoun-offset', 'A-offset', 'B-offset']].describe()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pronoun-offset</th>\n",
              "      <th>A-offset</th>\n",
              "      <th>B-offset</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.00000</td>\n",
              "      <td>2000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>324.963500</td>\n",
              "      <td>239.77800</td>\n",
              "      <td>300.535500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>98.788591</td>\n",
              "      <td>111.15768</td>\n",
              "      <td>113.226357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>16.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>274.000000</td>\n",
              "      <td>179.75000</td>\n",
              "      <td>237.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>316.000000</td>\n",
              "      <td>239.00000</td>\n",
              "      <td>294.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>370.000000</td>\n",
              "      <td>301.25000</td>\n",
              "      <td>358.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1135.000000</td>\n",
              "      <td>971.00000</td>\n",
              "      <td>1098.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Pronoun-offset    A-offset     B-offset\n",
              "count     2000.000000  2000.00000  2000.000000\n",
              "mean       324.963500   239.77800   300.535500\n",
              "std         98.788591   111.15768   113.226357\n",
              "min          3.000000     0.00000    16.000000\n",
              "25%        274.000000   179.75000   237.000000\n",
              "50%        316.000000   239.00000   294.000000\n",
              "75%        370.000000   301.25000   358.000000\n",
              "max       1135.000000   971.00000  1098.000000"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRppCMdznQYZ"
      },
      "source": [
        "The above stats really push the limits on what we'd be able to address what an RNN or LSTM would be able to accomplish on their own. Let's review the structure of the data again as well as the overall relatedness of what we're trying to handle and we could still consider an embedding for our usecase even after dropping out unnecessary words.\n",
        "\n",
        "After looking over the dataset more, I wanted to expand on my choices of why to treat this as a text scanning problem over a choice to treat this as a text embedding problem. As shown [here](https://machinelearningmastery.com/what-are-word-embeddings/), text embeddings will produce a vectorized distance in multidimensional space and give you an overall idea of how the data is clustered within that space reminiscent of PCA or K-Means clustering. It is good to note that embeddings themselves are incredibly great at performing dimensionality reduction and I would highly encorage their use in a different set of problem, but this I still think is overall more accurately addressed as a text scanning problem where the model can make use of the antecedents for accurate classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lc700NZ1tkSX"
      },
      "source": [
        "# Coming back to the modeling\n",
        "\n",
        "As mentioned in the project overview, our model needs to decide which of three results our model needs to produce (A, B, or neither). Let's provide a cleaned up dataset so we have something to talk to."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLcWJW85miOb"
      },
      "source": [
        "df_train = df_train.drop(columns=['Pronoun-offset', 'A-offset', 'B-offset'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "21dX75INvEGh",
        "outputId": "30023fb4-5185-4b8f-940d-e16ac99d3ce7"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Text</th>\n",
              "      <th>Pronoun</th>\n",
              "      <th>A</th>\n",
              "      <th>A-coref</th>\n",
              "      <th>B</th>\n",
              "      <th>B-coref</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>development-1</td>\n",
              "      <td>Zoe Telford -- played the police officer girlf...</td>\n",
              "      <td>her</td>\n",
              "      <td>Cheryl Cassidy</td>\n",
              "      <td>True</td>\n",
              "      <td>Pauline</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>development-2</td>\n",
              "      <td>He grew up in Evanston, Illinois the second ol...</td>\n",
              "      <td>His</td>\n",
              "      <td>MacKenzie</td>\n",
              "      <td>True</td>\n",
              "      <td>Bernard Leach</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>development-3</td>\n",
              "      <td>He had been reelected to Congress, but resigne...</td>\n",
              "      <td>his</td>\n",
              "      <td>Angeloz</td>\n",
              "      <td>False</td>\n",
              "      <td>De la Sota</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>development-4</td>\n",
              "      <td>The current members of Crime have also perform...</td>\n",
              "      <td>his</td>\n",
              "      <td>Hell</td>\n",
              "      <td>False</td>\n",
              "      <td>Henry Rosenthal</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>development-5</td>\n",
              "      <td>Her Santa Fe Opera debut in 2005 was as Nuria ...</td>\n",
              "      <td>She</td>\n",
              "      <td>Kitty Oppenheimer</td>\n",
              "      <td>False</td>\n",
              "      <td>Rivera</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              ID  ... B-coref\n",
              "0  development-1  ...   False\n",
              "1  development-2  ...   False\n",
              "2  development-3  ...    True\n",
              "3  development-4  ...    True\n",
              "4  development-5  ...    True\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FAfeKn9ve03"
      },
      "source": [
        "Above really focuses in on what we're trying to achieve overall in our modelling efforts. Make sure that a model scans a reduced text column, gives us an idea of whether the provided pronoun refers to A, B, or neither as described in the kaggle competition overview page.\n",
        "\n",
        "Given the number of specialist topics, I've been learning, I've not gotten much time into specifically modelling one given problem or another so this will be a healthy stretch for me as well.\n",
        "\n",
        "In particular, an LSTM cell will take a number of inputs as determined by the batch size we want to work with:\n",
        "\n",
        "![lstm-cell-state-description](https://drive.google.com/uc?export=view&id=1I2dgRZO_9DfiUpxG1io1fJ6-m_1mmpvj)\n",
        "\n",
        "and each token we use after data cleaning will be considered an input into this model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYD4kY2fr2B8"
      },
      "source": [
        "# Refining our idea of the model\n",
        "\n",
        "We've now figured out how we want to roughly handle the data inputs to the model and thus need to figure out what to do with the other data points. Remember that our model needs to produce a designation of which whether the pronoun coreferences A, B, or neither, which could be a C. In my mind, I'm really only looking to produce one of three at a given time, which I would then need to match my answer against as seen below. The tricky point for me is my first thought would be a many to one encoder-decoder architecture where the produced answer is compared against the true answer as part of a [custom loss function](https://neptune.ai/blog/keras-loss-functions).\n",
        "\n",
        "To clarify, let me show the exact set of data I'm referring to below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjG_oOqZvZzD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "eae2d85c-b12c-4e0d-9d55-e10ec276d7ec"
      },
      "source": [
        "df_train[['Pronoun', 'A', 'A-coref', 'B', 'B-coref']].head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pronoun</th>\n",
              "      <th>A</th>\n",
              "      <th>A-coref</th>\n",
              "      <th>B</th>\n",
              "      <th>B-coref</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>her</td>\n",
              "      <td>Cheryl Cassidy</td>\n",
              "      <td>True</td>\n",
              "      <td>Pauline</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>His</td>\n",
              "      <td>MacKenzie</td>\n",
              "      <td>True</td>\n",
              "      <td>Bernard Leach</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>his</td>\n",
              "      <td>Angeloz</td>\n",
              "      <td>False</td>\n",
              "      <td>De la Sota</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>his</td>\n",
              "      <td>Hell</td>\n",
              "      <td>False</td>\n",
              "      <td>Henry Rosenthal</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>She</td>\n",
              "      <td>Kitty Oppenheimer</td>\n",
              "      <td>False</td>\n",
              "      <td>Rivera</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Pronoun                  A  A-coref                B  B-coref\n",
              "0     her     Cheryl Cassidy     True          Pauline    False\n",
              "1     His          MacKenzie     True    Bernard Leach    False\n",
              "2     his            Angeloz    False       De la Sota     True\n",
              "3     his               Hell    False  Henry Rosenthal     True\n",
              "4     She  Kitty Oppenheimer    False           Rivera     True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mi_xe6lxeVv"
      },
      "source": [
        "Having broken down the data this far, we'd want to focus in on how the decoder architecture is going to produce token(s) and then address this problem as appropriate. Keep in mind the model will have access to the pronoun under consideration, so the pronoun field actualy becomes redundant in our entire consideration. Thus, we drop the pronoun field and even the coreferential fields and treat the loss function as a low regular expression. If the produced answer is in A, that wins. In B, that wins. Else, we have neither."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "fh0KIxcYwo1Z",
        "outputId": "73086fc1-aae0-45fe-f75e-538a8825675e"
      },
      "source": [
        "df_train[['A', 'B']].head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A</th>\n",
              "      <th>B</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Cheryl Cassidy</td>\n",
              "      <td>Pauline</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MacKenzie</td>\n",
              "      <td>Bernard Leach</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Angeloz</td>\n",
              "      <td>De la Sota</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Hell</td>\n",
              "      <td>Henry Rosenthal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Kitty Oppenheimer</td>\n",
              "      <td>Rivera</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   A                B\n",
              "0     Cheryl Cassidy          Pauline\n",
              "1          MacKenzie    Bernard Leach\n",
              "2            Angeloz       De la Sota\n",
              "3               Hell  Henry Rosenthal\n",
              "4  Kitty Oppenheimer           Rivera"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eT_8kx-Gzb7Z"
      },
      "source": [
        "df_train['A_len'] = df_train['A'].str.split(' ').str.len()\n",
        "df_train['B_len'] = df_train['B'].str.split(' ').str.len()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "MiK0y-ffz2pn",
        "outputId": "b41ef747-063f-42f4-b870-874032231789"
      },
      "source": [
        "df_train[['A_len', 'B_len']].describe()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A_len</th>\n",
              "      <th>B_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.526500</td>\n",
              "      <td>1.51250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.688138</td>\n",
              "      <td>0.66488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>7.000000</td>\n",
              "      <td>6.00000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             A_len       B_len\n",
              "count  2000.000000  2000.00000\n",
              "mean      1.526500     1.51250\n",
              "std       0.688138     0.66488\n",
              "min       1.000000     1.00000\n",
              "25%       1.000000     1.00000\n",
              "50%       1.000000     1.00000\n",
              "75%       2.000000     2.00000\n",
              "max       7.000000     6.00000"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuU1GFvq1V5O"
      },
      "source": [
        "Looking at the above, I'm going to take a look at how many different outliers there are in the data using a couple histogram plots. If there's a low level of overall samples going out into the high number of tokens, I can probably just drop the samples from the data and move on as it would save me a ton of time when it comes to training the model. Please do note that according to the GCP ML engineer cert, that ML is really meant to model even the strangest nuances in your data. My biggest thought is if that I can save myself a lot of trouble and processing power only having to consider 2 nodes on my decoder instead of 7 nodes. That'll be incredibly beneificial in the long run."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "jfDH2k3nz4ar",
        "outputId": "07d369eb-884e-444d-9aee-1e327bb1a710"
      },
      "source": [
        "df_train[['A_len', 'B_len']].hist()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f23873dd510>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f238740a410>]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsGf0CeE2swy"
      },
      "source": [
        "Very nicely, we have really small tails on both sides for the upper number of tokens. Let's repeat this for A_len and B_len for >= 3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkFOjFTz3GxX"
      },
      "source": [
        "len_df = df_train[['A_len', 'B_len']].copy()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "Y8YnTfj23MUN",
        "outputId": "a37e1cbb-2660-4fe6-ffb4-d51397f99fd6"
      },
      "source": [
        "le"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A_len</th>\n",
              "      <th>B_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      A_len  B_len\n",
              "0         2      1\n",
              "1         1      2\n",
              "2         1      3\n",
              "3         1      2\n",
              "4         2      1\n",
              "...     ...    ...\n",
              "1995      1      1\n",
              "1996      2      1\n",
              "1997      1      2\n",
              "1998      1      2\n",
              "1999      1      1\n",
              "\n",
              "[2000 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "qEWD_zRF3p1X",
        "outputId": "a1e7a508-dfed-40ff-f27e-50c8b1e9a202"
      },
      "source": [
        "len_df[len_df['A_len'] >= 3].hist()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f238613a310>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f2386141dd0>]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAVhUlEQVR4nO3dfbBkdZ3f8fdHRuTBh0EwN2SGcqZKig3ZETRTLBbGmvCQnQUC/EGxGErBZXd2q5TFdYyA+YOkSquwdo1idtc4AYRUWB5kYWXVMlCEG9fadVYGWHk0jAg4k4FBZdRBIxn85o8+Izfj7Znb3ffe033m/aq6dfuc7tPny+H0Z8799e/8fqkqJEnd8qq2C5AkzT/DXZI6yHCXpA4y3CWpgwx3Seogw12SOshwl6QOMtzHXJLrk3ys7TqkxeI5Pz8M9xYkmU7yQpLXtF2LtJCSPJXkZ0l2Nuf8l5Mc1XZd+wPDfZElWQH8C6CAs1otRloc/7qqXgscCTwH/KeW69kvGO6L773AN4DrgQsH3TjJmUkeTLIjyd8meeuM555K8uEk30ryoyS3JDlo/kqXhldV/we4DTh2kO0854djuC++9wI3Nj+/mWRqrhsmeRtwHfD7wOHA54A792jeOQ9YC6wE3gpcND9lS6NJcgjw2/Qubua6jef8kAz3RZTkncCbgVurahPwHeDfDPAW64DPVdXGqnq5qm4Afg6cOOM1n6mq/11VPwT+Gjh+nsqXhvVXSXYAPwJOA/54gG0954dkuC+uC4G7qur7zfJfMFjTzJuB9c2fpzuaD8xRwD+Z8ZpnZzz+KfDaUQqW5sE5VbUUOAj4APA/k/zjOW7rOT+kJW0XsL9IcjC9Px8PSLL7ZHwNsDTJcVX1D3N4m+8BH6+qjy9UndJCqaqXgduTfA54J732933xnB+SV+6L5xzgZXpfJh3f/PxT4G/otcPPxX8B/iDJb6Tn0CRnJHndglQszaPmnD0bOAx4bI6bec4PySv3xXMh8PmqembmyiR/CnwmyWVVtWtvb1BV9yX5PeBPgaOBnwFfB762QDVL8+Gvk7xMr/vv08CFVfXIXDb0nB9enIlJkrrHZhlJ6iDDfQwkeaS5PXvPnwvark1aCJ7zC89mGUnqoLH4QvWII46oFStWtF1GXy+++CKHHnpo22W0btyPw6ZNm75fVW9qu4658JyfDON+HPZ2zo9FuK9YsYL77ruv7TL6mp6eZs2aNW2X0bpxPw5Jnm67hrnynJ8M434c9nbO2+YuSR1kuEtSBxnuktRBhrskdZDhLkkdZLhLUgcZ7pLUQYa7JHWQ4S4NKMkfNWOjPJzkpiQHJVmZZGOSzc0kzQe2Xaf2b2Nxh+rerLj8ywNv89RVZyxAJRIkWQb8IXBsVf0sya3A+cDpwKeq6uYk/xm4GPjsMPvwnNd88MpdGtwS4OAkS4BDgG3AybwybdwN9Gbekloz9lfu0jipqq1J/gR4ht6sQHcBm4AdM2bS2gIs23PbJOuAdQBTU1NMT0/Puo/1q/Y6Ides+r3XsHbu3Dnv7zmJJvk4GO7SAJIcBpwNrAR2AF8A1s5l26raAGwAWL16dfUbkOqiYZplLpj9vYY17gNmLZZJPg42y0iDORX4blU9X1X/F7gdOAlY2jTTACwHtrZVoARzCPck1yXZnuThGev+OMnjSb6V5I4kS2c8d0XTY+DbSX5zoQqXWvIMcGKSQ5IEOAV4FLgXOLd5zYXAF1uqTwLmduV+Pb/6Z+fdwK9X1VuB/wVcAZDkWHo9B/5Zs82fJzlg3qqVWlZVG+l9cXo/8BC9z9AG4DLgQ0k2A4cD17ZWpMQc2tyr6mtJVuyx7q4Zi9/glSuWs4Gbq+rnwHebE/0E4O/mpVppDFTVlcCVe6x+kt65Lo2F+fhC9XeAW5rHy+iF/W6z9hoAew5MIo+DNDlGCvck/w7YBdw46Lb2HJg8Hgdpcgwd7kkuAs4ETqmqalZvBY6a8TJ7DUhSC4bqCplkLfAR4Kyq+umMp+4Ezk/ymiQrgaOBvx+9TEnSIPZ55Z7kJmANcESSLfS+SLoCeA1wd683GN+oqj+oqkeasTYepddc8/6qenmhipckzW4uvWXePcvqvt28qurjwMdHKUqSNBrvUJWkDjLcJamDDHdJ6iDDXZI6yHCXpA4y3CWpgwx3Seogw12SOshwl6QOMtwlqYMMd0nqIMNdGkCSY5I8OOPnx0k+mOSNSe5O8kTz+7C2a9X+zXCXBlBV366q46vqeOCfAz8F7gAuB+6pqqOBe5plqTWGuzS8U4DvVNXT9OYPvqFZfwNwTmtVSczPHKrS/up84Kbm8VRVbWsePwtM7fli5w2ePJN8HAx3aQhJDgTOojdxzf+nqipJzbLeeYMnzCQfB5tlpOH8FnB/VT3XLD+X5EiA5vf21iqTMNylYb2bV5pkoDd/8IXN4wuBLy56RdIMhrs0oCSHAqcBt89YfRVwWpIngFObZak1trlLA6qqF4HD91j3A3q9Z6Sx4JW7JHWQ4S5JHWS4S1IHGe6S1EH7DPck1yXZnuThGetmHSQpPZ9JsjnJt5K8fSGLlyTNbi5X7tcDa/dY12+QpN8Cjm5+1gGfnZ8yJUmD2Ge4V9XXgB/usbrfIElnA/+1er4BLN19154kafEM28+93yBJy4DvzXjdlmbdNvbgIEqTx+MgTY6Rb2LqN0jSHLZzEKUJ43GQJsewvWX6DZK0FThqxuuWN+skSYto2HDvN0jSncB7m14zJwI/mtF8I0laJPtslklyE7AGOCLJFuBKeoMi3ZrkYuBp4Lzm5V8BTgc205t+7H0LULMkaR/2Ge5V9e4+T/3KIElVVcD7Ry1KkjQa71CVpA4y3CWpgwx3Seogw10aUJKlSW5L8niSx5K8o994S1JbDHdpcFcDX62qXwOOAx6j/3hLUisMd2kASd4AvAu4FqCqXqqqHfQfb0lqhXOoSoNZCTwPfD7JccAm4FL6j7f0S46nNHkm+TgY7tJglgBvBy6pqo1JrmaPJph+4y05ntLkmeTjYLOMNJgtwJaq2tgs30Yv7PuNtyS1wnCXBlBVzwLfS3JMs+oU4FH6j7cktcJmGWlwlwA3JjkQeJLeGEqvYvbxlqRWGO7SgKrqQWD1LE/9ynhLUltslpGkDjLcJamDDHdJ6iDDXZI6yHCXpA4y3CWpgwx3Seogw12SOshwl6QOMtwlqYMMd0nqIMNdkjpopHBP8kdJHknycJKbkhyUZGWSjUk2J7mlGTlPkrSIhg73JMuAPwRWV9WvAwcA5wOfAD5VVW8BXgAuno9CJUlzN2qzzBLg4CRLgEOAbcDJ9GanAScKlqRWDD2ee1VtTfInwDPAz4C76E0WvKOqds/wuwVYNtv2ThY8eTwO0uQYOtyTHAacTW82+B3AF4C1c93eyYInj8dBmhyjzMR0KvDdqnoeIMntwEnA0iRLmqv35cDW0cuUxkeSp4CfAC8Du6pqdZI3ArcAK4CngPOq6oW2apyrFX0untav2tX3wuqpq85YyJI0T0Zpc38GODHJIUnCKxMF3wuc27zGiYLVVf+yqo6vqt3T7V0O3FNVRwP3NMtSa4YO96raSO+L0/uBh5r32gBcBnwoyWbgcODaeahTGndn0+tAAHYk0BgYaYLsqroSuHKP1U8CJ4zyvtKYK+CuJAV8rvn+aKqqtjXPPwtM7bnROHYi6LevqYP7P7c/fak+yZ0IRgp3aT/1zqa32D8C7k7y+Mwnq6qa4GeP9WPXiaDfvtav2sUnH5o9Hua7w8I4m+ROBA4/IA2oqrY2v7cDd9D7S/W5JEcCNL+3t1ehZLhLA0lyaJLX7X4M/CvgYeBOeh0IwI4EGgM2y0iDmQLu6HUQYwnwF1X11STfBG5NcjHwNHBeizVKhrs0iKp6EjhulvU/oNcdWBoLNstIUgcZ7pLUQYa7JHWQ4S5JHWS4S1IHGe6S1EGGuyR1kOEuSR1kuEtSBxnuktRBhrskdZDhLkkdZLhLUgcZ7pLUQYa7JHWQ4S5JHWS4SwNKckCSB5J8qVlemWRjks1JbklyYNs1Soa7NLhLgcdmLH8C+FRVvQV4Abi4laqkGQx3aQBJlgNnANc0ywFOBm5rXnIDcE471UmvGCnckyxNcluSx5M8luQdSd6Y5O4kTzS/D5uvYqUx8GngI8AvmuXDgR1VtatZ3gIsa6MwaaZRJ8i+GvhqVZ3btDMeAnwUuKeqrkpyOXA5cNmI+5Fal+RMYHtVbUqyZojt1wHrAKamppienp71detX7Zp1/d70e6996bevqYP7PzfsvibRzp07J/a/d+hwT/IG4F3ARQBV9RLwUpKzgTXNy24ApjHc1Q0nAWclOR04CHg9vQucpUmWNFfvy4Gts21cVRuADQCrV6+uNWvWzLqTiy7/8sCFPXXB7O+1L/32tX7VLj750OzxMOy+JtH09DT9/j+Nu1Gu3FcCzwOfT3IcsIneF01TVbWtec2zwNRsG4/jVUw/k/yv93za349DVV0BXAHQXLl/uKouSPIF4FzgZuBC4IutFSk1Rgn3JcDbgUuqamOSq+k1wfxSVVWSmm3jcbyK6WeS//WeTx6Hvi4Dbk7yMeAB4NqW65FGCvctwJaq2tgs30Yv3J9LcmRVbUtyJLB91CKlcVNV0/SaHKmqJ4ET2qxH2tPQvWWq6lnge0mOaVadAjwK3EnvT1PwT1RJasWovWUuAW5seso8CbyP3j8Ytya5GHgaOG/EfUiSBjRSuFfVg8DqWZ46ZZT3lSSNxjtUJamDDHdJ6iDDXZI6yHCXpA4y3CWpgwx3Seogw12SOshwl6QOMtwlqYMMd0nqIMNdkjrIcJekDjLcJamDDHdJ6iDDXRpAkoOS/H2Sf0jySJL/0KxfmWRjks1JbmnmOJBaY7hLg/k5cHJVHQccD6xNciLwCeBTVfUW4AXg4hZrlAx3aRDVs7NZfHXzU8DJ9OYRBrgBOKeF8qRfGnWaPWm/k+QAYBPwFuDPgO8AO6pqV/OSLcCyWbZbB6wDmJqaYnp6etb3X79q16zr96bfe+1Lv31NHdz/uWH3NYl27tw5sf+9hrs0oKp6GTg+yVLgDuDX5rjdBmADwOrVq2vNmjWzvu6iy788cE1PXTD7e+1Lv32tX7WLTz40ezwMu69JND09Tb//T+POZhlpSFW1A7gXeAewNMnuNFwObG2tMAnDXRpIkjc1V+wkORg4DXiMXsif27zsQuCL7VQo9dgsIw3mSOCGpt39VcCtVfWlJI8CNyf5GPAAcG2bRUqGuzSAqvoW8LZZ1j8JnLD4FUmzs1lGkjpo5HBPckCSB5J8qVn2Tj1Jatl8XLlfSu8Lpd28U0+SWjZSuCdZDpwBXNMsB+/Uk6TWjXrl/mngI8AvmuXDmcOdepKkhTV0b5kkZwLbq2pTkjVDbD92t2L3M8m3IM8nj4M0OUbpCnkScFaS04GDgNcDV9Pcqddcvfe9U28cb8XuZ5JvQZ5PHgdpcgzdLFNVV1TV8qpaAZwP/I+qugDv1JOk1i1EP/fLgA8l2UyvDd479SRpkc3LHapVNQ1MN4+9U0+SWuYdqpLUQYa7JHWQ4S5JHWS4S1IHGe6S1EGGuyR1kOEuSR1kuEsDSHJUknuTPJrkkSSXNuvfmOTuJE80vw9ru1bt3wx3aTC7gPVVdSxwIvD+JMcClwP3VNXRwD3NstQaw10aQFVtq6r7m8c/oTdRzTLgbHrzF4DzGGgMOEG2NKQkK+hNlr0RmKqqbc1TzwJTs7x+7Ia57revqYP7P7c/Dfs8ycNcG+7SEJK8FvhL4INV9ePeJGQ9VVVJas9txnGY6377Wr9qF598aPZ4mO8htcfZJA9zbbOMNKAkr6YX7DdW1e3N6ueSHNk8fySwva36JDDcpYE08wRfCzxWVf9xxlN30pu/AJzHQGPAZhlpMCcB7wEeSvJgs+6jwFXArUkuBp4GzmupPgkw3KWBVNXXgfR5+pTFrEXaG5tlJKmDDHdJ6iDDXZI6yHCXpA7yC1VJY2nFMDdzXXXGAlQymbxyl6QOMtwlqYMMd0nqINvcG3tr31u/alffAZZs45M0joa+cndGGkkaX6M0yzgjjSSNqaHD3RlpJGl8zUub+6Az0jTbjNWsNHvbj7PS9EzyrDTS/mbkcB9mRprmubGalWZv+3FWmp5JnpVG2t+M1BXSGWkkaTyN0lvGGWkkaUyNcuW+e0aak5M82PycTm9GmtOSPAGc2ixLnZDkuiTbkzw8Y53dfzV2Rukt8/WqSlW9taqOb36+UlU/qKpTquroqjq1qn44nwVLLbseWLvHOrv/auw4/IA0gKr6GrDnBYvdfzV2HH5AGt1Edv/d277GofvvYh6Hfia5+6/hLs2jSer+u7d9jUP338U8Dv1Mcvdfm2Wk0dn9V2PHcJdGZ/dfjR3DXRpAkpuAvwOOSbIlycXY/VdjyDZ3aQBV9e4+T52yqIVI++CVuyR1kOEuSR1kuEtSBxnuktRBhrskdZDhLkkdZLhLUgcZ7pLUQYa7JHWQ4S5JHWS4S1IHGe6S1EGGuyR1kOEuSR1kuEtSBzme+4RYMcx8kledsQCVSN3T7/O1ftWuvnO5jvvnyyt3SeqgBbtyT7IWuBo4ALimqpx6TJ3mOa99Wcy/wBck3JMcAPwZcBqwBfhmkjur6tGF2J8mU5eamjznNW4WqlnmBGBzVT1ZVS8BNwNnL9C+pHHgOa+xkqqa/zdNzgXWVtXvNsvvAX6jqj4w4zXrgHXN4jHAt+e9kPlzBPD9tosYA+N+HN5cVW9qY8ee85017seh7znfWm+ZqtoAbGhr/4NIcl9VrW67jrZ5HEbjOT95Jvk4LFSzzFbgqBnLy5t1Uld5zmusLFS4fxM4OsnKJAcC5wN3LtC+pHHgOa+xsiDNMlW1K8kHgP9Or1vYdVX1yELsa5FMxJ/Si8Dj0IfnfGdN7HFYkC9UJUnt8g5VSeogw12SOshw34ckByR5IMmX2q6lTUmWJrktyeNJHkvyjrZr0vxLclSSe5M8muSRJJe2XVObJvnz76iQ+3Yp8Bjw+rYLadnVwFer6tymN8ghbRekBbELWF9V9yd5HbApyd378TAKE/v598p9L5IsB84Armm7ljYleQPwLuBagKp6qap2tFuVFkJVbauq+5vHP6EXbMvaraodk/75N9z37tPAR4BftF1Iy1YCzwOfb/5EvSbJoW0XpYWVZAXwNmBju5W0ZqI//4Z7H0nOBLZX1aa2axkDS4C3A5+tqrcBLwKXt1uSFlKS1wJ/CXywqn7cdj2LrQuff8O9v5OAs5I8RW+Ev5OT/Ld2S2rNFmBLVe2+gruNXtirg5K8ml6w31hVt7ddT0sm/vPvTUxzkGQN8OGqOrPtWtqS5G+A362qbyf598ChVfVvWy5L8yxJgBuAH1bVB9uuZxxM6uff3jKaq0uAG5ueMk8C72u5Hi2Mk4D3AA8lebBZ99Gq+kqLNWkIXrlLUgfZ5i5JHWS4S1IHGe6S1EGGuyR1kOEuSR1kuEtSBxnuktRB/w8AAOJYYi77hgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "vGFo0zry5M8t",
        "outputId": "3ab698c2-251d-44bb-e620-789b0cf166c8"
      },
      "source": [
        "len_df[len_df['B_len'] >= 3].hist()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f2386019e10>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f2386044890>]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvNfHd8p5-Oj"
      },
      "source": [
        "In this problem, I'd end up dropping out about 60 samples and would definitely want to get buyin from the business before just doing this. If you have someone that knows the nuances of the data in production, now would be a very great time to ask them for their opinion on how often coreferences with larger names appear in the actual output. Personally, though, I feel like this is a great tradeoff for the longer term though when we want to construct a continuous training and inference pipeline on something like kubeflow. No sense in making the business pay more than necessary for just the right amount of stuff that it needs.\n",
        "\n",
        "For more detail, here's a rough drawing from an [article](https://towardsdatascience.com/how-to-implement-seq2seq-lstm-model-in-keras-shortcutnlp-6f355f3e5639) by Akira Takezawa on towardsdatascience.com:\n",
        "![seq2seq-model](https://drive.google.com/uc?export=view&id=1-09fxkhToEsiE9A2gYgSBQ4ZyqsPWHBy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXiSMwFHAtRG"
      },
      "source": [
        "Finally another great picture of doing the seq2seq model with an embedding as shown here from [Guru99](https://www.guru99.com/seq2seq-model.html):\n",
        "![seq2seq-embedding](https://drive.google.com/uc?export=view&id=1-5xW0pK3yKwR9xFNYv9xU_ttMWRSvK4p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kh13akssBli7"
      },
      "source": [
        "Overall, I think we've completed a good problem exploration and refinement session. We can decide in later sessions whether we want to use an embedding in our data cleaning, pre-trained or not. Really a fun few hours though."
      ]
    }
  ]
}